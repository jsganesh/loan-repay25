{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# filename: loanpredict.py\n# Kaggle S5E11 â€“ Loan Payback\n# Lean signal pipeline with numeric-only LightGBM matrix and native-categorical CatBoost.\n\nimport os\nimport warnings\nfrom typing import List, Tuple\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.isotonic import IsotonicRegression\n\nfrom catboost import CatBoostClassifier, Pool\nimport lightgbm as lgb\n\nwarnings.filterwarnings(\"ignore\")\nSEED, N_FOLDS = 42, 5\n\ndef load_data(target_col=\"loan_paid_back\", id_col=\"id\"):\n    train_path = \"train.csv\" if os.path.exists(\"train.csv\") else \"/kaggle/input/playground-series-s5e11/train.csv\"\n    test_path  = \"test.csv\"  if os.path.exists(\"test.csv\")  else \"/kaggle/input/playground-series-s5e11/test.csv\"\n    train, test = pd.read_csv(train_path), pd.read_csv(test_path)\n    assert target_col in train.columns\n    assert id_col in train.columns and id_col in test.columns\n    y = train[target_col].astype(float)\n    X = train.drop(columns=[target_col])\n    test_ids = test[id_col].copy()\n    return X, y, test, test_ids\n\ndef engineer(df: pd.DataFrame) -> pd.DataFrame:\n    out = df.copy()\n    for c in [\"annual_income\", \"debt_to_income_ratio\", \"credit_score\", \"loan_amount\", \"interest_rate\"]:\n        if c in out.columns:\n            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n\n    if {\"loan_amount\", \"annual_income\"}.issubset(out.columns):\n        out[\"loan_to_income\"] = out[\"loan_amount\"] / (out[\"annual_income\"] + 1.0)\n        out[\"log_loan_to_income\"] = np.log1p(out[\"loan_to_income\"].clip(lower=0))\n\n    if {\"interest_rate\", \"debt_to_income_ratio\"}.issubset(out.columns):\n        out[\"interest_burden\"] = out[\"interest_rate\"] * out[\"debt_to_income_ratio\"]\n\n    if \"credit_score\" in out.columns:\n        cs = out[\"credit_score\"].astype(float)\n        out[\"credit_score_norm\"] = (cs - cs.min()) / (cs.max() - cs.min() + 1e-9)\n\n    if \"grade_subgrade\" in out.columns:\n        g = out[\"grade_subgrade\"].astype(str)\n        out[\"grade_letter\"] = g.str[0]\n        letter_map = {\"A\": 6, \"B\": 5, \"C\": 4, \"D\": 3, \"E\": 2, \"F\": 1}\n        out[\"grade_letter_ord\"] = out[\"grade_letter\"].map(letter_map).fillna(3).astype(int)\n\n    if {\"loan_to_income\", \"interest_rate\"}.issubset(out.columns):\n        out[\"lti_x_int\"] = out[\"loan_to_income\"] * out[\"interest_rate\"]\n    if {\"debt_to_income_ratio\", \"loan_to_income\"}.issubset(out.columns):\n        out[\"dti_x_lti\"] = out[\"debt_to_income_ratio\"] * out[\"loan_to_income\"]\n    return out\n\ndef infer_cats(df: pd.DataFrame, max_card=64) -> List[str]:\n    cats = []\n    for c in df.columns:\n        if df[c].dtype == \"object\":\n            cats.append(c)\n        elif pd.api.types.is_integer_dtype(df[c]) and df[c].nunique() <= max_card:\n            cats.append(c)\n    return cats\n\ndef target_mean_encode_cv(X: pd.DataFrame, y: pd.Series, T: pd.DataFrame, cols: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    X_enc, T_enc = X.copy(), T.copy()\n    global_mean = y.mean()\n    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\n    for col in cols:\n        oof = np.zeros(len(X))\n        full_map = y.groupby(X[col]).mean()\n        T_map = T[col].map(full_map).fillna(global_mean)\n        for tr_idx, val_idx in skf.split(X, y):\n            fold_map = y.iloc[tr_idx].groupby(X.iloc[tr_idx][col]).mean()\n            oof[val_idx] = X.iloc[val_idx][col].map(fold_map).fillna(global_mean).values\n        X_enc[f\"{col}_tgtmean\"] = oof\n        T_enc[f\"{col}_tgtmean\"] = T_map.values\n    return X_enc, T_enc\n\ndef build_lgb_numeric_matrix(X_te: pd.DataFrame, T_te: pd.DataFrame, residual_cats: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Create strictly numeric matrices for LightGBM:\n    - Label-encode residual categorical columns (objects).\n    - Drop ALL remaining object dtype columns.\n    \"\"\"\n    X_le, T_le = X_te.copy(), T_te.copy()\n    for c in residual_cats:\n        if X_le[c].dtype == \"object\":\n            le = LabelEncoder()\n            combined = pd.concat([X_le[c].astype(str), T_le[c].astype(str)], axis=0)\n            le.fit(combined)\n            X_le[c] = le.transform(X_le[c].astype(str))\n            T_le[c] = le.transform(T_le[c].astype(str))\n    # Drop any remaining object columns (including original high-signal categorical columns)\n    obj_cols_X = [c for c in X_le.columns if X_le[c].dtype == \"object\"]\n    obj_cols_T = [c for c in T_le.columns if T_le[c].dtype == \"object\"]\n    drop_cols = list(set(obj_cols_X + obj_cols_T))\n    if drop_cols:\n        X_le = X_le.drop(columns=drop_cols)\n        T_le = T_le.drop(columns=drop_cols)\n    # Final assurance: no objects remain\n    bad = [c for c in X_le.columns if X_le[c].dtype == \"object\"]\n    if bad:\n        raise ValueError(f\"LGB matrix still has object dtypes: {bad}\")\n    return X_le, T_le\n\nCAT_PARAMS = {\n    \"loss_function\": \"Logloss\",\n    \"eval_metric\": \"AUC\",\n    \"learning_rate\": 0.035,\n    \"depth\": 7,\n    \"l2_leaf_reg\": 4.0,\n    \"iterations\": 3500,\n    \"bootstrap_type\": \"Bayesian\",\n    \"random_seed\": SEED,\n    \"verbose\": False,\n}\nLGB_PARAMS = {\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"learning_rate\": 0.03,\n    \"num_leaves\": 48,\n    \"feature_fraction\": 0.85,\n    \"bagging_fraction\": 0.85,\n    \"bagging_freq\": 1,\n    \"min_data_in_leaf\": 60,\n    \"lambda_l2\": 8.0,\n    \"lambda_l1\": 0.0,\n    \"max_depth\": -1,\n    \"n_estimators\": 2600,\n    \"random_state\": SEED,\n    \"verbosity\": -1,\n}\ndef build_monotone_constraints(columns: List[str]) -> List[int]:\n    pos = {\"interest_rate\", \"debt_to_income_ratio\", \"loan_to_income\"}\n    neg = {\"credit_score_norm\", \"grade_letter_ord\"}\n    return [1 if c in pos else (-1 if c in neg else 0) for c in columns]\n\nBLEND_W_CB, BLEND_W_LGB = 0.68, 0.32\n\ndef run():\n    X_raw, y, T_raw, test_ids = load_data()\n    X, T = engineer(X_raw), engineer(T_raw)\n    common = [c for c in X.columns if c in T.columns]\n    X, T = X[common].copy(), T[common].copy()\n\n    cat_cols = infer_cats(X)\n    for c in cat_cols:\n        X[c] = X[c].astype(\"object\").fillna(\"__MISSING__\")\n        T[c] = T[c].astype(\"object\").fillna(\"__MISSING__\")\n\n    # Target-mean encode strongest categoricals\n    high_signal = [c for c in [\"grade_subgrade\", \"loan_purpose\", \"employment_status\"] if c in cat_cols]\n    X_te, T_te = target_mean_encode_cv(X, y, T, high_signal)\n\n    # Build numeric-only matrices for LightGBM\n    residual_cats = [c for c in cat_cols if c not in high_signal]\n    X_lgb, T_lgb = build_lgb_numeric_matrix(X_te, T_te, residual_cats)\n\n    # Constraints aligned to LGB matrix columns\n    mono = build_monotone_constraints(list(X_lgb.columns))\n\n    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n    oof_cb = np.zeros(len(X))\n    oof_lgb = np.zeros(len(X))\n\n    cat_indices = [X.columns.get_loc(c) for c in cat_cols]\n\n    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n        print(f\"Fold {fold}/{N_FOLDS}\")\n\n        cb = CatBoostClassifier(**CAT_PARAMS)\n        cb.fit(\n            Pool(X.iloc[tr_idx], label=y.iloc[tr_idx], cat_features=cat_indices if cat_indices else None),\n            eval_set=Pool(X.iloc[val_idx], label=y.iloc[val_idx], cat_features=cat_indices if cat_indices else None),\n            use_best_model=True,\n            verbose=False,\n        )\n        preds_cb = cb.predict_proba(Pool(X.iloc[val_idx], cat_features=cat_indices if cat_indices else None))[:, 1]\n        oof_cb[val_idx] = preds_cb\n        print(f\"  CatBoost AUC: {roc_auc_score(y.iloc[val_idx], preds_cb):.5f}\")\n\n        lgbm = lgb.LGBMClassifier(**LGB_PARAMS, monotone_constraints=mono)\n        lgbm.fit(\n            X_lgb.iloc[tr_idx], y.iloc[tr_idx],\n            eval_set=[(X_lgb.iloc[val_idx], y.iloc[val_idx])],\n            eval_metric=\"auc\",\n            callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)],\n        )\n        preds_lgb = lgbm.predict_proba(X_lgb.iloc[val_idx])[:, 1]\n        oof_lgb[val_idx] = preds_lgb\n        print(f\"  LightGBM AUC: {roc_auc_score(y.iloc[val_idx], preds_lgb):.5f}\")\n\n        blend_fold = BLEND_W_CB * preds_cb + BLEND_W_LGB * preds_lgb\n        print(f\"  Blend AUC:    {roc_auc_score(y.iloc[val_idx], blend_fold):.5f}\")\n\n    auc_cb = roc_auc_score(y, oof_cb)\n    auc_lgb = roc_auc_score(y, oof_lgb)\n    oof_blend = BLEND_W_CB * oof_cb + BLEND_W_LGB * oof_lgb\n    auc_blend = roc_auc_score(y, oof_blend)\n    print(f\"\\nOOF CatBoost AUC: {auc_cb:.5f}\")\n    print(f\"OOF LightGBM AUC: {auc_lgb:.5f}\")\n    print(f\"OOF Blend AUC:    {auc_blend:.5f}\")\n\n    iso = IsotonicRegression(out_of_bounds=\"clip\").fit(oof_blend, y.values)\n\n    cb_full = CatBoostClassifier(**CAT_PARAMS)\n    cb_full.fit(Pool(X, label=y, cat_features=cat_indices if cat_indices else None), verbose=False)\n\n    lgb_full = lgb.LGBMClassifier(**LGB_PARAMS, monotone_constraints=mono)\n    lgb_full.fit(X_lgb, y)\n\n    test_cb = cb_full.predict_proba(Pool(T, cat_features=cat_indices if cat_indices else None))[:, 1]\n    test_lgb = lgb_full.predict_proba(T_lgb)[:, 1]\n    test_blend = BLEND_W_CB * test_cb + BLEND_W_LGB * test_lgb\n    test_blend_cal = np.clip(iso.predict(test_blend), 0.0, 1.0)\n\n    pd.DataFrame({\"id\": test_ids, \"loan_paid_back\": test_blend_cal}).to_csv(\"submission.csv\", index=False)\n    print(\"\\nSaved submission.csv\")\n\nif __name__ == \"__main__\":\n    run()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}