{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2044a009",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-09T23:19:50.159675Z",
     "iopub.status.busy": "2025-11-09T23:19:50.159291Z",
     "iopub.status.idle": "2025-11-10T00:19:43.455712Z",
     "shell.execute_reply": "2025-11-10T00:19:43.454470Z"
    },
    "papermill": {
     "duration": 3593.303397,
     "end_time": "2025-11-10T00:19:43.458387",
     "exception": false,
     "start_time": "2025-11-09T23:19:50.154990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "  LGB rank AUC: 0.92299\n",
      "Fold 2/5\n",
      "  LGB rank AUC: 0.92244\n",
      "Fold 3/5\n",
      "  LGB rank AUC: 0.92102\n",
      "Fold 4/5\n",
      "  LGB rank AUC: 0.92192\n",
      "Fold 5/5\n",
      "  LGB rank AUC: 0.92137\n",
      "\n",
      "OOF LGB rank AUC: 0.92195\n",
      "Pseudo-labels selected: 24459\n",
      "\n",
      "Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "# filename: lgb_rank_pseudolabel.py\n",
    "# Kaggle S5E11 — Loan Payback\n",
    "# Radical CPU-only pipeline (≤ ~4 hours):\n",
    "#   - LightGBM multi-seed rank ensemble\n",
    "#   - Fold-wise smoothed target + frequency encodings (leakage-safe)\n",
    "#   - Extreme pseudo-labeling of test (p ≥ 0.995 → 1, p ≤ 0.005 → 0), capped\n",
    "#   - Refit single LightGBM on augmented data\n",
    "#   - Rank-averaged inference + isotonic calibration → submission.csv\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "from itertools import cycle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "N_FOLDS = 5                         # 5 folds for speed + stability\n",
    "TARGET_COL = \"loan_paid_back\"\n",
    "ID_COL = \"id\"\n",
    "\n",
    "SEEDS = [42, 2025, 777, 131, 902]   # 5 seeds; modest diversity\n",
    "LR_SWEEP = [0.028, 0.030, 0.032]    # tiny LR sweep\n",
    "\n",
    "# Stability-biased leaf pairs (≥ half min_data_in_leaf ≥ 60)\n",
    "LEAF_GRID = [(80, 60), (80, 60), (76, 60), (72, 55)]\n",
    "\n",
    "# Pseudo-label thresholds and cap\n",
    "PL_POS_TH = 0.995\n",
    "PL_NEG_TH = 0.005\n",
    "PL_MAX_RATIO = 0.20  # ≤ 20% of training size\n",
    "\n",
    "BASE_LGB_PARAMS = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 80,         # overwritten per pair\n",
    "    \"feature_fraction\": 0.90,\n",
    "    \"bagging_fraction\": 0.90,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"min_data_in_leaf\": 60,   # overwritten per pair\n",
    "    \"lambda_l2\": 8.0,\n",
    "    \"lambda_l1\": 0.0,\n",
    "    \"max_depth\": -1,\n",
    "    \"n_estimators\": 2200,     # early stopping trims\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "# ------------------------------\n",
    "# IO\n",
    "# ------------------------------\n",
    "def load_data() -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    train_path = \"train.csv\" if os.path.exists(\"train.csv\") else \"/kaggle/input/playground-series-s5e11/train.csv\"\n",
    "    test_path  = \"test.csv\"  if os.path.exists(\"test.csv\")  else \"/kaggle/input/playground-series-s5e11/test.csv\"\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    y = train[TARGET_COL].astype(float)\n",
    "    X = train.drop(columns=[TARGET_COL])\n",
    "    test_ids = test[ID_COL].copy()\n",
    "    return X, y, test, test_ids\n",
    "\n",
    "# ------------------------------\n",
    "# Features\n",
    "# ------------------------------\n",
    "NUM_BASE = [\"annual_income\",\"debt_to_income_ratio\",\"credit_score\",\"loan_amount\",\"interest_rate\"]\n",
    "CAT_BASE = [\"gender\",\"marital_status\",\"education_level\",\"employment_status\",\"loan_purpose\",\"grade_subgrade\"]\n",
    "\n",
    "def engineer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # Numeric safety\n",
    "    for c in NUM_BASE:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "    # Grade parsing\n",
    "    if \"grade_subgrade\" in out.columns:\n",
    "        g = out[\"grade_subgrade\"].astype(str)\n",
    "        out[\"grade_letter\"] = g.str[0]\n",
    "        out[\"subgrade_num\"] = pd.to_numeric(g.str[1:], errors=\"coerce\").fillna(3)\n",
    "        letter_map = {\"A\":6,\"B\":5,\"C\":4,\"D\":3,\"E\":2,\"F\":1}\n",
    "        out[\"grade_letter_ord\"] = out[\"grade_letter\"].map(letter_map).fillna(3).astype(int)\n",
    "\n",
    "    # Ratios / interactions\n",
    "    if {\"loan_amount\",\"annual_income\"}.issubset(out.columns):\n",
    "        out[\"loan_to_income\"] = out[\"loan_amount\"] / (out[\"annual_income\"] + 1.0)\n",
    "        out[\"log_loan_to_income\"] = np.log1p(out[\"loan_to_income\"].clip(lower=0))\n",
    "    if {\"interest_rate\",\"debt_to_income_ratio\"}.issubset(out.columns):\n",
    "        out[\"interest_burden\"] = out[\"interest_rate\"] * out[\"debt_to_income_ratio\"]\n",
    "    if \"credit_score\" in out.columns:\n",
    "        cs = out[\"credit_score\"].astype(float)\n",
    "        out[\"credit_score_norm\"] = (cs - cs.min()) / (cs.max() - cs.min() + 1e-9)\n",
    "    if {\"loan_to_income\",\"interest_rate\"}.issubset(out.columns):\n",
    "        out[\"lti_x_int\"] = out[\"loan_to_income\"] * out[\"interest_rate\"]\n",
    "    if {\"debt_to_income_ratio\",\"loan_to_income\"}.issubset(out.columns):\n",
    "        out[\"dti_x_lti\"] = out[\"debt_to_income_ratio\"] * out[\"loan_to_income\"]\n",
    "\n",
    "    # Purpose-grade interaction\n",
    "    if {\"grade_letter_ord\",\"loan_purpose\"}.issubset(out.columns):\n",
    "        out[\"purpose_grade\"] = out[\"grade_letter_ord\"] * out[\"loan_purpose\"].astype(str).factorize()[0]\n",
    "\n",
    "    # Categorical hygiene\n",
    "    for c in CAT_BASE + [\"grade_letter\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].astype(str).fillna(\"__MISSING__\")\n",
    "\n",
    "    return out\n",
    "\n",
    "def infer_cats(df: pd.DataFrame, max_card: int = 64) -> List[str]:\n",
    "    cats = []\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            cats.append(c)\n",
    "        elif pd.api.types.is_integer_dtype(df[c]) and df[c].nunique() <= max_card:\n",
    "            cats.append(c)\n",
    "    return cats\n",
    "\n",
    "# ------------------------------\n",
    "# Fold-wise encodings (smoothed target + frequency)\n",
    "# ------------------------------\n",
    "def fold_smoothed_target_encode(X: pd.DataFrame, y: pd.Series, T: pd.DataFrame, col: str,\n",
    "                                n_splits: int = N_FOLDS, prior: int = 10, seed: int = SEED) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X_col = X[col].astype(str); T_col = T[col].astype(str)\n",
    "    X_enc = np.zeros(len(X))\n",
    "    global_mean = y.mean()\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for tr_idx, val_idx in skf.split(X, y):\n",
    "        te_map = y.iloc[tr_idx].groupby(X_col.iloc[tr_idx]).agg(['mean','count'])\n",
    "        smooth = (te_map['mean'] * te_map['count'] + global_mean * prior) / (te_map['count'] + prior)\n",
    "        mapping = smooth.to_dict()\n",
    "        X_enc[val_idx] = X_col.iloc[val_idx].map(mapping).fillna(global_mean).values\n",
    "    full_map = y.groupby(X_col).agg(['mean','count'])\n",
    "    full_smooth = (full_map['mean'] * full_map['count'] + global_mean * prior) / (full_map['count'] + prior)\n",
    "    T_enc = T_col.map(full_smooth.to_dict()).fillna(global_mean).values\n",
    "    return X_enc, T_enc\n",
    "\n",
    "def fold_frequency_encode(X: pd.DataFrame, y: pd.Series, T: pd.DataFrame, col: str,\n",
    "                          n_splits: int = N_FOLDS, seed: int = SEED) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X_col = X[col].astype(str); T_col = T[col].astype(str)\n",
    "    X_freq = np.zeros(len(X))\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for tr_idx, val_idx in skf.split(X, y):\n",
    "        freq = X_col.iloc[tr_idx].value_counts().to_dict()\n",
    "        X_freq[val_idx] = X_col.iloc[val_idx].map(freq).fillna(0).values\n",
    "    full_freq = X_col.value_counts().to_dict()\n",
    "    T_freq = T_col.map(full_freq).fillna(0).values\n",
    "    return X_freq, T_freq\n",
    "\n",
    "# ------------------------------\n",
    "# LGB params builder with tiny jitters\n",
    "# ------------------------------\n",
    "def build_params(base: dict, seed: int, lr: float, leaves: int, leaf_min: int) -> dict:\n",
    "    p = base.copy()\n",
    "    p[\"random_state\"] = seed\n",
    "    p[\"learning_rate\"] = lr\n",
    "    p[\"num_leaves\"] = leaves\n",
    "    p[\"min_data_in_leaf\"] = leaf_min\n",
    "    frac_jitter = 0.02\n",
    "    l2_jitter   = 0.10\n",
    "    if seed % 2 == 0:\n",
    "        p[\"feature_fraction\"] = min(0.92, base[\"feature_fraction\"] + frac_jitter)\n",
    "        p[\"lambda_l2\"] = base[\"lambda_l2\"] * (1.0 + l2_jitter)\n",
    "    else:\n",
    "        p[\"feature_fraction\"] = max(0.88, base[\"feature_fraction\"] - frac_jitter)\n",
    "        p[\"lambda_l2\"] = base[\"lambda_l2\"] * (1.0 - l2_jitter)\n",
    "    return p\n",
    "\n",
    "def to_rank(a: np.ndarray) -> np.ndarray:\n",
    "    order = a.argsort()\n",
    "    ranks = np.empty_like(order, dtype=float)\n",
    "    ranks[order] = np.linspace(0.0, 1.0, len(a), endpoint=True)\n",
    "    return ranks\n",
    "\n",
    "# ------------------------------\n",
    "# Rank ensemble (CV)\n",
    "# ------------------------------\n",
    "def rank_ensemble_cv(X_lgb: pd.DataFrame, y: pd.Series, T_lgb: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    oof_ranks_sum = np.zeros(len(X_lgb))\n",
    "    fold_count = np.zeros(len(X_lgb))\n",
    "    test_rank_list_all_folds = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_lgb, y), start=1):\n",
    "        print(f\"Fold {fold}/{N_FOLDS}\")\n",
    "        val_ranks = []\n",
    "        leaf_cycle = cycle(LEAF_GRID)\n",
    "        combos = list(zip(SEEDS, LR_SWEEP + LR_SWEEP[:max(0, len(SEEDS)-len(LR_SWEEP))]))\n",
    "        for s, lr in combos:\n",
    "            leaves, leaf_min = next(leaf_cycle)\n",
    "            params = build_params(BASE_LGB_PARAMS, seed=s, lr=lr, leaves=leaves, leaf_min=leaf_min)\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(\n",
    "                X_lgb.iloc[tr_idx], y.iloc[tr_idx],\n",
    "                eval_set=[(X_lgb.iloc[val_idx], y.iloc[val_idx])],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n",
    "            )\n",
    "            val_pred = model.predict_proba(X_lgb.iloc[val_idx])[:, 1]\n",
    "            val_ranks.append(to_rank(val_pred))\n",
    "\n",
    "            test_pred = model.predict_proba(T_lgb)[:, 1]\n",
    "            test_rank_list_all_folds.append(to_rank(test_pred))\n",
    "\n",
    "        avg_val_ranks = np.mean(val_ranks, axis=0)\n",
    "        oof_ranks_sum[val_idx] += avg_val_ranks\n",
    "        fold_count[val_idx] += 1\n",
    "        print(f\"  LGB rank AUC: {roc_auc_score(y.iloc[val_idx], avg_val_ranks):.5f}\")\n",
    "\n",
    "    oof_ranks = np.zeros(len(X_lgb))\n",
    "    mask = fold_count > 0\n",
    "    oof_ranks[mask] = oof_ranks_sum[mask] / fold_count[mask]\n",
    "\n",
    "    # Average all test ranks collected per seed per fold\n",
    "    test_ranks = np.mean(np.vstack(test_rank_list_all_folds), axis=0)\n",
    "    oof_auc = roc_auc_score(y, oof_ranks)\n",
    "    return oof_ranks, test_ranks, oof_auc\n",
    "\n",
    "# ------------------------------\n",
    "# Pseudo-label extremes\n",
    "# ------------------------------\n",
    "def select_pseudo_labels(test_prob: np.ndarray, pos_th: float, neg_th: float, max_ratio: float, train_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    pos_idx = np.where(test_prob >= pos_th)[0]\n",
    "    neg_idx = np.where(test_prob <= neg_th)[0]\n",
    "    pl_idx = np.concatenate([pos_idx, neg_idx])\n",
    "\n",
    "    cap = int(max_ratio * train_size)\n",
    "    if len(pl_idx) > cap:\n",
    "        pl_idx = pl_idx[:cap]\n",
    "\n",
    "    if len(pl_idx) == 0:\n",
    "        return np.array([], dtype=int), np.array([], dtype=float)\n",
    "\n",
    "    pl_labels = np.where(test_prob[pl_idx] >= pos_th, 1.0, 0.0)\n",
    "    return pl_idx, pl_labels\n",
    "\n",
    "# ------------------------------\n",
    "# Full refit on augmented data (single pass)\n",
    "# ------------------------------\n",
    "def refit_on_augmented(X_lgb: pd.DataFrame, y: pd.Series, T_lgb: pd.DataFrame,\n",
    "                       pl_idx: np.ndarray, pl_labels: np.ndarray) -> np.ndarray:\n",
    "    # Build augmented dataset\n",
    "    X_pl = T_lgb.iloc[pl_idx]\n",
    "    y_pl = pl_labels\n",
    "    X_aug = pd.concat([X_lgb, X_pl], axis=0, ignore_index=True)\n",
    "    y_aug = np.concatenate([y.values, y_pl], axis=0)\n",
    "\n",
    "    # Train a single model per seed/LR pair and rank-average on test\n",
    "    test_rank_list = []\n",
    "    leaf_cycle = cycle(LEAF_GRID)\n",
    "    combos = list(zip(SEEDS, LR_SWEEP + LR_SWEEP[:max(0, len(SEEDS)-len(LR_SWEEP))]))\n",
    "    for s, lr in combos:\n",
    "        leaves, leaf_min = next(leaf_cycle)\n",
    "        params = build_params(BASE_LGB_PARAMS, seed=s, lr=lr, leaves=leaves, leaf_min=leaf_min)\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_aug, y_aug)\n",
    "        test_pred = model.predict_proba(T_lgb)[:, 1]\n",
    "        test_rank_list.append(to_rank(test_pred))\n",
    "\n",
    "    test_ranks_final = np.mean(np.vstack(test_rank_list), axis=0)\n",
    "    return test_ranks_final\n",
    "\n",
    "# ------------------------------\n",
    "# Main\n",
    "# ------------------------------\n",
    "def main():\n",
    "    # Load and engineer\n",
    "    X_raw, y, T_raw, test_ids = load_data()\n",
    "    X = engineer(X_raw)\n",
    "    T = engineer(T_raw)\n",
    "\n",
    "    # Fold-wise encodes on strong categoricals\n",
    "    cat_cols = [c for c in [\"grade_letter\",\"subgrade_num\",\"loan_purpose\",\"employment_status\",\"education_level\",\"marital_status\"] if c in X.columns]\n",
    "    X_enc, T_enc = X.copy(), T.copy()\n",
    "    for col in cat_cols:\n",
    "        prior = 20 if col in {\"employment_status\",\"education_level\"} else 10\n",
    "        x_te, t_te = fold_smoothed_target_encode(X, y, T, col, n_splits=N_FOLDS, prior=prior, seed=SEED)\n",
    "        x_fe, t_fe = fold_frequency_encode(X, y, T, col, n_splits=N_FOLDS, seed=SEED)\n",
    "        X_enc[f\"{col}_te_smooth\"] = x_te;   T_enc[f\"{col}_te_smooth\"] = t_te\n",
    "        X_enc[f\"{col}_freq\"] = x_fe;        T_enc[f\"{col}_freq\"] = t_fe\n",
    "\n",
    "    # Categories as pandas 'category'\n",
    "    cat_all = infer_cats(X_enc)\n",
    "    for c in cat_all:\n",
    "        if X_enc[c].dtype == \"object\":\n",
    "            X_enc[c] = X_enc[c].astype(\"category\")\n",
    "            T_enc[c] = T_enc[c].astype(\"category\")\n",
    "\n",
    "    # CV rank ensemble\n",
    "    oof_ranks, test_ranks, oof_auc = rank_ensemble_cv(X_enc, y, T_enc)\n",
    "    print(f\"\\nOOF LGB rank AUC: {oof_auc:.5f}\")\n",
    "\n",
    "    # Calibrate ranks to probabilities\n",
    "    iso = IsotonicRegression(out_of_bounds=\"clip\").fit(oof_ranks, y.values)\n",
    "    test_prob = np.clip(iso.predict(test_ranks), 0.0, 1.0)\n",
    "\n",
    "    # Extreme pseudo-labels\n",
    "    pl_idx, pl_labels = select_pseudo_labels(test_prob, PL_POS_TH, PL_NEG_TH, PL_MAX_RATIO, train_size=len(X_enc))\n",
    "    print(f\"Pseudo-labels selected: {len(pl_idx)}\")\n",
    "\n",
    "    if len(pl_idx) > 0:\n",
    "        # Refit on augmented data and rank-average again\n",
    "        test_ranks_final = refit_on_augmented(X_enc, y, T_enc, pl_idx, pl_labels)\n",
    "        test_prob_final = np.clip(iso.predict(test_ranks_final), 0.0, 1.0)\n",
    "    else:\n",
    "        test_prob_final = test_prob\n",
    "\n",
    "    # Submission\n",
    "    pd.DataFrame({ID_COL: test_ids, TARGET_COL: test_prob_final}).to_csv(\"submission.csv\", index=False)\n",
    "    print(\"\\nSaved submission.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14262372,
     "sourceId": 91722,
     "sourceType": "competition"
    },
    {
     "datasetId": 902,
     "sourceId": 370089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8678604,
     "sourceId": 13651350,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8678647,
     "sourceId": 13651405,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3599.158206,
   "end_time": "2025-11-10T00:19:44.385263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-09T23:19:45.227057",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
