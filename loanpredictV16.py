{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91722,"databundleVersionId":14262372,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# filename: lp18.py\n# Kaggle S5E11 — Loan Payback (FAST)\n# 5-fold CV, strict OOF target encoding (5 categoricals),\n# minimal features, CatBoost + LightGBM,\n# rank-averaged blend (OOF weight search) + isotonic calibration.\n# Tuned for ≤ ~2 hours CPU runtime (no GPU).\n\nimport os\nimport warnings\nfrom typing import List, Tuple\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.isotonic import IsotonicRegression\n\nfrom catboost import CatBoostClassifier, Pool\nimport lightgbm as lgb\n\nwarnings.filterwarnings(\"ignore\")\n\nSEED = 42\nN_FOLDS = 5  # faster than 7; still robust\n\n# ------------------------------\n# Data\n# ------------------------------\ndef load_data(target_col=\"loan_paid_back\", id_col=\"id\"):\n    train_path = \"train.csv\" if os.path.exists(\"train.csv\") else \"/kaggle/input/playground-series-s5e11/train.csv\"\n    test_path  = \"test.csv\"  if os.path.exists(\"test.csv\")  else \"/kaggle/input/playground-series-s5e11/test.csv\"\n    train, test = pd.read_csv(train_path), pd.read_csv(test_path)\n    y = train[target_col].astype(float)\n    X = train.drop(columns=[target_col])\n    test_ids = test[id_col].copy()\n    return X, y, test, test_ids\n\n# ------------------------------\n# Features (minimal, high-signal)\n# ------------------------------\ndef engineer(df: pd.DataFrame) -> pd.DataFrame:\n    out = df.copy()\n\n    for c in [\"annual_income\",\"debt_to_income_ratio\",\"credit_score\",\"loan_amount\",\"interest_rate\"]:\n        if c in out.columns:\n            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n\n    if {\"loan_amount\",\"annual_income\"}.issubset(out.columns):\n        out[\"loan_to_income\"] = out[\"loan_amount\"] / (out[\"annual_income\"] + 1.0)\n        out[\"log_loan_to_income\"] = np.log1p(out[\"loan_to_income\"].clip(lower=0))\n\n    if {\"interest_rate\",\"debt_to_income_ratio\"}.issubset(out.columns):\n        out[\"interest_burden\"] = out[\"interest_rate\"] * out[\"debt_to_income_ratio\"]\n\n    if \"credit_score\" in out.columns:\n        cs = out[\"credit_score\"].astype(float)\n        out[\"credit_score_norm\"] = (cs - cs.min()) / (cs.max() - cs.min() + 1e-9)\n\n    if \"grade_subgrade\" in out.columns:\n        g = out[\"grade_subgrade\"].astype(str)\n        out[\"grade_letter\"] = g.str[0]\n        letter_map = {\"A\":6,\"B\":5,\"C\":4,\"D\":3,\"E\":2,\"F\":1}\n        out[\"grade_letter_ord\"] = out[\"grade_letter\"].map(letter_map).fillna(3).astype(int)\n\n    if {\"loan_to_income\",\"interest_rate\"}.issubset(out.columns):\n        out[\"lti_x_int\"] = out[\"loan_to_income\"] * out[\"interest_rate\"]\n    if {\"debt_to_income_ratio\",\"loan_to_income\"}.issubset(out.columns):\n        out[\"dti_x_lti\"] = out[\"debt_to_income_ratio\"] * out[\"loan_to_income\"]\n\n    return out\n\ndef infer_cats(df: pd.DataFrame, max_card=64) -> List[str]:\n    cats = []\n    for c in df.columns:\n        if df[c].dtype == \"object\":\n            cats.append(c)\n        elif pd.api.types.is_integer_dtype(df[c]) and df[c].nunique() <= max_card:\n            cats.append(c)\n    return cats\n\n# ------------------------------\n# Strict OOF target mean encoding\n# ------------------------------\ndef target_mean_encode_cv(\n    X: pd.DataFrame, y: pd.Series, T: pd.DataFrame, cols: List[str], n_splits: int = N_FOLDS, seed: int = SEED\n) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    X_enc, T_enc = X.copy(), T.copy()\n    global_mean = y.mean()\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n\n    for col in cols:\n        X_col = X[col].astype(str)\n        T_col = T[col].astype(str)\n\n        oof_vals = np.zeros(len(X))\n        full_map = y.groupby(X_col).mean()\n        T_map = T_col.map(full_map).fillna(global_mean)\n\n        for tr_idx, val_idx in skf.split(X, y):\n            fold_map = y.iloc[tr_idx].groupby(X_col.iloc[tr_idx]).mean()\n            mapped = X_col.iloc[val_idx].map(fold_map).fillna(global_mean)\n            oof_vals[val_idx] = mapped.values\n\n        X_enc[f\"{col}_tgtmean\"] = oof_vals\n        T_enc[f\"{col}_tgtmean\"] = T_map.values\n\n    return X_enc, T_enc\n\n# ------------------------------\n# Models (lean, with early stopping)\n# ------------------------------\nCAT_PARAMS = {\n    \"loss_function\":\"Logloss\",\n    \"eval_metric\":\"AUC\",\n    \"learning_rate\":0.03,\n    \"depth\":6,               # shallower -> faster\n    \"l2_leaf_reg\":6.0,\n    \"iterations\":2200,       # lower -> faster\n    \"bootstrap_type\":\"Bayesian\",\n    \"random_seed\":SEED,\n    \"verbose\":False,\n    \"od_type\":\"Iter\",\n    \"od_wait\":300,           # early stopping patience\n}\n\nLGB_PARAMS = {\n    \"objective\":\"binary\",\n    \"metric\":\"auc\",\n    \"learning_rate\":0.03,\n    \"num_leaves\":64,         # moderate capacity\n    \"feature_fraction\":0.9,\n    \"bagging_fraction\":0.9,\n    \"bagging_freq\":1,\n    \"min_data_in_leaf\":50,\n    \"lambda_l2\":6.0,\n    \"lambda_l1\":0.0,\n    \"max_depth\":-1,\n    \"n_estimators\":2200,     # lower -> faster\n    \"random_state\":SEED,\n    \"verbosity\":-1,\n}\n\ndef to_rank(a: np.ndarray) -> np.ndarray:\n    order = a.argsort()\n    ranks = np.empty_like(order, dtype=float)\n    ranks[order] = np.linspace(0.0, 1.0, len(a), endpoint=True)\n    return ranks\n\n# ------------------------------\n# Training\n# ------------------------------\ndef run():\n    X_raw, y, T_raw, test_ids = load_data()\n    X, T = engineer(X_raw), engineer(T_raw)\n    common = [c for c in X.columns if c in T.columns]\n    X, T = X[common].copy(), T[common].copy()\n\n    # categoricals\n    cat_cols = infer_cats(X)\n    for c in cat_cols:\n        X[c] = X[c].astype(\"object\").fillna(\"__MISSING__\")\n        T[c] = T[c].astype(\"object\").fillna(\"__MISSING__\")\n\n    # high-signal cats to target-encode (5 total)\n    high_signal = [c for c in [\"grade_subgrade\",\"loan_purpose\",\"employment_status\",\"marital_status\",\"education_level\"] if c in cat_cols]\n    X_te, T_te = target_mean_encode_cv(X, y, T, high_signal, n_splits=N_FOLDS, seed=SEED)\n\n    # CatBoost input: raw cats + TE numerics\n    cb_cat_idx = [X_te.columns.get_loc(c) for c in cat_cols if c in X_te.columns]\n\n    # LightGBM input: category dtype + TE numerics (no constraints)\n    X_lgb, T_lgb = X_te.copy(), T_te.copy()\n    for c in cat_cols:\n        if X_lgb[c].dtype == \"object\":\n            X_lgb[c] = X_lgb[c].astype(\"category\")\n            T_lgb[c] = T_lgb[c].astype(\"category\")\n\n    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n    oof_cb = np.zeros(len(X))\n    oof_lgb = np.zeros(len(X))\n\n    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n        print(f\"Fold {fold}/{N_FOLDS}\")\n\n        cb = CatBoostClassifier(**CAT_PARAMS)\n        cb.fit(\n            Pool(X_te.iloc[tr_idx], label=y.iloc[tr_idx], cat_features=cb_cat_idx if cb_cat_idx else None),\n            eval_set=Pool(X_te.iloc[val_idx], label=y.iloc[val_idx], cat_features=cb_cat_idx if cb_cat_idx else None),\n            use_best_model=True,\n            verbose=False\n        )\n        preds_cb = cb.predict_proba(Pool(X_te.iloc[val_idx], cat_features=cb_cat_idx if cb_cat_idx else None))[:,1]\n        oof_cb[val_idx] = preds_cb\n        print(f\"  CatBoost AUC: {roc_auc_score(y.iloc[val_idx], preds_cb):.5f}\")\n\n        lgbm = lgb.LGBMClassifier(**LGB_PARAMS)\n        lgbm.fit(\n            X_lgb.iloc[tr_idx], y.iloc[tr_idx],\n            eval_set=[(X_lgb.iloc[val_idx], y.iloc[val_idx])],\n            eval_metric=\"auc\",\n            callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n        )\n        preds_lgb = lgbm.predict_proba(X_lgb.iloc[val_idx])[:,1]\n        oof_lgb[val_idx] = preds_lgb\n        print(f\"  LightGBM AUC: {roc_auc_score(y.iloc[val_idx], preds_lgb):.5f}\")\n\n    # Rank-averaged OOF blend and weight search (small grid = fast)\n    r_cb = to_rank(oof_cb)\n    r_lgb = to_rank(oof_lgb)\n    best_w, best_auc = None, -1.0\n    for w in np.linspace(0.35, 0.65, 7):  # CatBoost rank weight\n        r_blend = w*r_cb + (1.0-w)*r_lgb\n        auc = roc_auc_score(y, r_blend)\n        if auc > best_auc:\n            best_auc, best_w = auc, w\n    print(f\"\\nBest OOF rank blend: weight_cb={best_w:.3f}, AUC={best_auc:.5f}\")\n\n    # Calibrate rank blend to probabilities\n    r_blend_oof = best_w*r_cb + (1.0-best_w)*r_lgb\n    iso = IsotonicRegression(out_of_bounds=\"clip\").fit(r_blend_oof, y.values)\n\n    # Full fits (fast schedules)\n    cb_full = CatBoostClassifier(**CAT_PARAMS)\n    cb_full.fit(Pool(X_te, label=y, cat_features=cb_cat_idx if cb_cat_idx else None), verbose=False)\n\n    lgb_full = lgb.LGBMClassifier(**LGB_PARAMS)\n    lgb_full.fit(X_lgb, y)\n\n    # Test predictions, rank blend, calibration\n    test_cb = cb_full.predict_proba(Pool(T_te, cat_features=cb_cat_idx if cb_cat_idx else None))[:,1]\n    test_lgb = lgb_full.predict_proba(T_lgb)[:,1]\n    r_cb_test = to_rank(test_cb)\n    r_lgb_test = to_rank(test_lgb)\n    r_blend_test = best_w*r_cb_test + (1.0-best_w)*r_lgb_test\n    test_prob = np.clip(iso.predict(r_blend_test), 0.0, 1.0)\n\n    pd.DataFrame({\"id\": test_ids, \"loan_paid_back\": test_prob}).to_csv(\"submission.csv\", index=False)\n    print(\"\\nSaved submission.csv\")\n\nif __name__ == \"__main__\":\n    run()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}